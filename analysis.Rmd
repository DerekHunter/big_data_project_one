---
title: "Project_01"
author: "Group_1"
date: "March 21, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy = TRUE)
```

```{r include = FALSE, echo = FALSE}
library(glmnet)
library(randomForest)
```

```{r include = FALSE, echo = FALSE, warning = FALSE}
    loadData = function(path){
      tmpData = read.csv(path)
      tmpData = subset(tmpData, select = -Id)
      
      tmpData$MSSubClass = as.factor(tmpData$MSSubClass);#Factor encoded as a numeric value
      for(column in colnames(tmpData)){
        if(class(tmpData[[column]]) == "factor"){
          tmpData[column] = factor(tmpData[[column]], levels=c("None", levels(tmpData[[column]])))
          tmpData[[column]][is.na(tmpData[[column]])] = "None"
        }else{
          tmpData[column][is.na(tmpData[column])] = 0;
        }
      }
      return (tmpData)
    }


train = loadData("./train.csv")
test = loadData("./test.csv")

# sum(is.na(train))
# sum(is.na(test))
    
levels(train$MSSubClass) = c("None", "20",  "30",  "40",  "45",  "50",  "60",  "70",  "75",  "80",  "85",  "90",  "120", "150", "160", "180", "190")
```


```{r, fig.height=6, cache=TRUE}

rf1 = randomForest(x = train[, 1:79], y = train$SalePrice, importance = TRUE, data = train)

varImpPlot(rf1)

# testpredrf1 = predict(rf1, test)
# testpredrf1 = cbind(1461:2919, testpredrf1)
# colnames(testpredrf1) = c("Id", "SalePrice")
# write.csv(testpredrf1, file = "testpredrf1.csv", row.names = FALSE)

# sum(sapply(train[, 1:79], class) == sapply(test[, 1:79], class))
```

The predictor variables that showed to have some effect and for which we plan to use for a linear regression model are Overall Quality, Neighbohood, External Quality, above ground square feet, and size of garage in car capacity. Most of these factors make a lot of sense as to why the sales price would be affected. Better quality, better neighborhood, and larger square feet intuitively should increase the sales price. However, the size of the garage does seem a bit suprizing considering all the other factors that were measured.  

```{r}
mse = function(linmod) sum(linmod$residuals^2)/linmod$df.residual
```

Created a function to calculate the MSE for our linear models.

```{r include = FALSE, echo = FALSE}
# # Linear model using all of the variables
# lm1 = lm(SalePrice ~ ., data = train)
# anova(lm1)
# mse(lm1)
# sqrt(mse(lm1))
# 
# # 10-fold crossvalidation 
# Sales.xval = rep(0, nrow(train))
# xvs = rep(1:10, length = nrow(train))
# xvs = sample(xvs)
# for (i in 1:10) {
#   xvstest = train[xvs == i,]
#   xvstrain = train[xvs != i,]
#   glub = lm(SalePrice ~ ., data = xvstrain)
#   Sales.xval[xvs == i] = predict(glub, xvstest)
#   if (i == 10) print(sum((train$SalePrice - Sales.xval)^2)/glub$df.residual)
# }

# testpred1 = predict(lm1, test) # There are no MSSubClass 190 in the training data, but there are 31 in the testing data. The linear model doesn't know how to handle these observations.
# length(testpred1)
# length(1461:2919)
# testpred1 = cbind(1461:2919, testpred1)
# colnames(testpred1) = c("Id", "SalePrice")
# write.csv(testpred1, file = "testpred1.csv", row.names = FALSE)
```

```{r, fig.height=6}
# Linear model using important variables from RF selection IncNodePurity
lm2 = lm(SalePrice ~ OverallQual + Neighborhood + GrLivArea + ExterQual + GarageCars, data = train)
anova(lm2)
mse(lm2)
sqrt(mse(lm2))
summary(lm2)[8]
summary(lm2)[9]

Sales.xval = rep(0, nrow(train))
xvs = rep(1:10, length = nrow(train))
xvs = sample(xvs)
for (i in 1:10) {
  xvstest = train[xvs == i,]
  xvstrain = train[xvs != i,]
  glub = lm(SalePrice ~ OverallQual + Neighborhood + GrLivArea + ExterQual + GarageCars, data = xvstrain)
  Sales.xval[xvs == i] = predict(glub, xvstest)
  if (i == 10) print(sum((train$SalePrice - Sales.xval)^2)/glub$df.residual)
}

testpred2 = predict(lm2, test)
length(testpred2)
length(1461:2919)
testpred2 = cbind(1461:2919, testpred2)
colnames(testpred2) = c("Id", "SalePrice")
# write.csv(testpred2, file = "testpred2.csv", row.names = FALSE)

par(mfrow = c(2, 2))
plot(lm2)
```

```{r include = FALSE, echo = FALSE}
# # Linear model using important variables from RF selection %IncMSE
# lm3 = lm(SalePrice ~ GrLivArea + Neighborhood + OverallQual + TotalBsmtSF + MSSubClass, data = train)
# anova(lm3)
# mse(lm3)
# sqrt(mse(lm3))
# 
# Sales.xval = rep(0, nrow(train))
# xvs = rep(1:10, length = nrow(train))
# xvs = sample(xvs)
# for (i in 1:10) {
#   xvstest = train[xvs == i,]
#   xvstrain = train[xvs != i,]
#   glub = lm(SalePrice ~ GrLivArea + Neighborhood + OverallQual + TotalBsmtSF + MSSubClass, data = xvstrain)
#   Sales.xval[xvs == i] = predict(glub, xvstest)
#   if (i == 10) print(sum((train$SalePrice - Sales.xval)^2)/glub$df.residual)
# }
# 
# testpred3 = predict(lm3, test) # There are no MSSubClass 190 in the training data, but there are 31 in the testing data. The linear model doesn't know how to handle these observations.
# summary(train$MSSubClass)
# summary(test$MSSubClass)
```

After performing a Random Forest variable selection, the IncNodePurity variable importance plot showed the top five variables of OverallQual, Neighborhood, GrLivArea, ExterQual, GarageCars. These make sense intuitively as good predictors for the sale price of a home as stated above. We ran a linear model, called lm2, and calculated the root MSE as 34843.58. Although this linear model violates the assumptions of normality and nonconstant variance as seen in the diagnostic plots, we accept it as a baseline for futher models. We submitted an entry to Kaggle, and ranked 1769 out of 2055. `r round(1769/2055, 2)*100`% of entries have a lower root mean squared logged error. Additionally, the linear model's $R^2$ = 0.812, and the adjusted $R^2$ = 0.808.